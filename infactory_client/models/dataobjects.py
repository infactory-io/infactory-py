# coding: utf-8

"""
    Find the knowledge in your data

    <h2><img src='/logo.svg' alt='Infactory' height='50'></h2><p><ul><li><a href='/er.svg'>Entity-Relationship Diagram</a></li><li><a href='/er.md'>Documentation</a></li></ul></p>

    The version of the OpenAPI document: 0.5.0
    Contact: support@infactory.ai
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class Dataobjects(BaseModel):
    """
    Represents a dataobjects record
    """ # noqa: E501
    id: StrictStr
    bucket: StrictStr
    key: StrictStr
    file_type: Optional[StrictStr] = None
    file_size: Optional[StrictInt] = None
    etag: Optional[StrictStr] = None
    mime_type: Optional[StrictStr] = None
    metadata: Optional[Any] = None
    datasource_id: StrictStr
    created_at: datetime
    updated_at: datetime
    deleted_at: Optional[datetime] = None
    downstream_lineage: Optional[List[Datalineage]] = None
    upstream_lineage: Optional[List[Datalineage]] = None
    datalines: Optional[List[Datalines]] = None
    datasources: Optional[Datasources] = None
    queryprograms: Optional[List[Queryprograms]] = None
    __properties: ClassVar[List[str]] = ["id", "bucket", "key", "file_type", "file_size", "etag", "mime_type", "metadata", "datasource_id", "created_at", "updated_at", "deleted_at", "downstream_lineage", "upstream_lineage", "datalines", "datasources", "queryprograms"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of Dataobjects from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of metadata
        if self.metadata:
            _dict['metadata'] = self.metadata.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in downstream_lineage (list)
        _items = []
        if self.downstream_lineage:
            for _item_downstream_lineage in self.downstream_lineage:
                if _item_downstream_lineage:
                    _items.append(_item_downstream_lineage.to_dict())
            _dict['downstream_lineage'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in upstream_lineage (list)
        _items = []
        if self.upstream_lineage:
            for _item_upstream_lineage in self.upstream_lineage:
                if _item_upstream_lineage:
                    _items.append(_item_upstream_lineage.to_dict())
            _dict['upstream_lineage'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in datalines (list)
        _items = []
        if self.datalines:
            for _item_datalines in self.datalines:
                if _item_datalines:
                    _items.append(_item_datalines.to_dict())
            _dict['datalines'] = _items
        # override the default output from pydantic by calling `to_dict()` of datasources
        if self.datasources:
            _dict['datasources'] = self.datasources.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in queryprograms (list)
        _items = []
        if self.queryprograms:
            for _item_queryprograms in self.queryprograms:
                if _item_queryprograms:
                    _items.append(_item_queryprograms.to_dict())
            _dict['queryprograms'] = _items
        # set to None if file_type (nullable) is None
        # and model_fields_set contains the field
        if self.file_type is None and "file_type" in self.model_fields_set:
            _dict['file_type'] = None

        # set to None if file_size (nullable) is None
        # and model_fields_set contains the field
        if self.file_size is None and "file_size" in self.model_fields_set:
            _dict['file_size'] = None

        # set to None if etag (nullable) is None
        # and model_fields_set contains the field
        if self.etag is None and "etag" in self.model_fields_set:
            _dict['etag'] = None

        # set to None if mime_type (nullable) is None
        # and model_fields_set contains the field
        if self.mime_type is None and "mime_type" in self.model_fields_set:
            _dict['mime_type'] = None

        # set to None if metadata (nullable) is None
        # and model_fields_set contains the field
        if self.metadata is None and "metadata" in self.model_fields_set:
            _dict['metadata'] = None

        # set to None if deleted_at (nullable) is None
        # and model_fields_set contains the field
        if self.deleted_at is None and "deleted_at" in self.model_fields_set:
            _dict['deleted_at'] = None

        # set to None if downstream_lineage (nullable) is None
        # and model_fields_set contains the field
        if self.downstream_lineage is None and "downstream_lineage" in self.model_fields_set:
            _dict['downstream_lineage'] = None

        # set to None if upstream_lineage (nullable) is None
        # and model_fields_set contains the field
        if self.upstream_lineage is None and "upstream_lineage" in self.model_fields_set:
            _dict['upstream_lineage'] = None

        # set to None if datalines (nullable) is None
        # and model_fields_set contains the field
        if self.datalines is None and "datalines" in self.model_fields_set:
            _dict['datalines'] = None

        # set to None if datasources (nullable) is None
        # and model_fields_set contains the field
        if self.datasources is None and "datasources" in self.model_fields_set:
            _dict['datasources'] = None

        # set to None if queryprograms (nullable) is None
        # and model_fields_set contains the field
        if self.queryprograms is None and "queryprograms" in self.model_fields_set:
            _dict['queryprograms'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of Dataobjects from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "id": obj.get("id"),
            "bucket": obj.get("bucket"),
            "key": obj.get("key"),
            "file_type": obj.get("file_type"),
            "file_size": obj.get("file_size"),
            "etag": obj.get("etag"),
            "mime_type": obj.get("mime_type"),
            "metadata": AnyOf.from_dict(obj["metadata"]) if obj.get("metadata") is not None else None,
            "datasource_id": obj.get("datasource_id"),
            "created_at": obj.get("created_at"),
            "updated_at": obj.get("updated_at"),
            "deleted_at": obj.get("deleted_at"),
            "downstream_lineage": [Datalineage.from_dict(_item) for _item in obj["downstream_lineage"]] if obj.get("downstream_lineage") is not None else None,
            "upstream_lineage": [Datalineage.from_dict(_item) for _item in obj["upstream_lineage"]] if obj.get("upstream_lineage") is not None else None,
            "datalines": [Datalines.from_dict(_item) for _item in obj["datalines"]] if obj.get("datalines") is not None else None,
            "datasources": Datasources.from_dict(obj["datasources"]) if obj.get("datasources") is not None else None,
            "queryprograms": [Queryprograms.from_dict(_item) for _item in obj["queryprograms"]] if obj.get("queryprograms") is not None else None
        })
        return _obj

from infactory_client.models.datalineage import Datalineage
from infactory_client.models.datalines import Datalines
from infactory_client.models.datasources import Datasources
from infactory_client.models.queryprograms import Queryprograms
# TODO: Rewrite to not use raise_errors
Dataobjects.model_rebuild(raise_errors=False)

